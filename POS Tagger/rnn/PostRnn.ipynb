{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PostRnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB_MuuS5KuR1",
        "outputId": "bfd7c196-ef94-4aa8-8b28-7bcb25b1d97f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# install necessary packages using pip\n",
        "!pip install keras numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Id_Qap4PBG"
      },
      "source": [
        "!wget -cq http://www.hlt.utdallas.edu/~moldovan/CS6320.20F/train.zip\n",
        "!unzip -qq train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT37l9LMoGYx",
        "outputId": "d0d695e5-2e1e-429d-c710-392fb9648c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os\n",
        "import gzip\n",
        "def load_corpus(path):\n",
        "  if not os.path.isdir(path):\n",
        "    sys.exit(\"Input path is not a directory\")\n",
        "  tuplesList = []\n",
        "  tagSet = ['NOUN', 'PRONOUN', 'VERB', 'ADVERB', 'ADJECTIVE', 'CONJUNCTION','PREPOSITION', 'DETERMINER', 'NUMBER', 'PUNCT', 'X']\n",
        "  for filename in os.listdir(path):\n",
        "    filename = os.path.join(path, filename)\n",
        "    try:\n",
        "      with gzip.open(filename, 'rt') as reader:\n",
        "        lines = reader.read().splitlines()\n",
        "        for line in lines:\n",
        "          lineTuples = []\n",
        "          items = line.split()\n",
        "          if(len(items) > 0):\n",
        "            for item in items:\n",
        "              [token, tag] = item.split('/')\n",
        "              tag = tag if tag in tagSet else 'X'\n",
        "              lineTuples.append((token.lower(), tag))\n",
        "            tuplesList.append(lineTuples)\n",
        "    except IOError:\n",
        "      sys.exit(\"Cannot read file\")\n",
        "  return tuplesList\n",
        "\n",
        "\n",
        "# test the function here:\n",
        "path = \"/content/train\" # fill in the path\n",
        "data = load_corpus(path)\n",
        "print (data[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('miraculously', 'ADVERB'), (',', 'PUNCT'), ('she', 'PRONOUN'), ('found', 'VERB'), ('exactly', 'ADVERB'), ('the', 'DETERMINER'), ('right', 'ADJECTIVE'), ('statement', 'NOUN'), ('.', 'PUNCT')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFJvfGCPois_",
        "outputId": "5e75fe78-bf95-4a83-f92a-263e17eef715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np # convert lists to np arrays before returning them\n",
        "\n",
        "def create_dataset(sentences):\n",
        "  train_X, train_y = list(), list()\n",
        "  word2idx, tag2idx = dict(), dict() # dictionaries that will provide word/tag to integer mapping\n",
        "  \"\"\"\n",
        "  Construct two lists: train_X and train_y that will be used to train your RNN. Input to the function will be the output of previous function\n",
        "  \"\"\"\n",
        "  wordSet = set()\n",
        "  tagSet = set()\n",
        "  for line in sentences:\n",
        "    for item in line:\n",
        "      wordSet.add(item[0])\n",
        "      tagSet.add(item[1])\n",
        "\n",
        "  for idx, word in enumerate(wordSet,1):\n",
        "    word2idx[word] = idx\n",
        "  for idx, tag in enumerate(tagSet,1):\n",
        "    tag2idx[tag] = idx\n",
        "\n",
        "  word2idx['[PAD]'] = 0\n",
        "  tag2idx['[PAD]'] = 0\n",
        "  \n",
        "  for line in sentences:\n",
        "    x = []\n",
        "    y = []\n",
        "    for item in line:\n",
        "      x.append(word2idx[item[0]])\n",
        "      y.append(tag2idx[item[1]])\n",
        "    train_X.append(x)\n",
        "    train_y.append(y)\n",
        "\n",
        "  train_X= np.array(train_X)\n",
        "  train_y = np.array(train_y)\n",
        "  idx2tag = {}\n",
        "  for t in tag2idx:\n",
        "    idx2tag[tag2idx[t]] = t\n",
        "\n",
        "\n",
        "  return train_X, train_y, word2idx, tag2idx, idx2tag # you may also want to output the word and tag dictionaries created for evaluation\n",
        "\n",
        "# test the function\n",
        "train_X, train_y, word2idx, tag2idx, idx2tag = create_dataset(data)\n",
        "print (train_X[0], train_y[0])\n",
        "print(tag2idx)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[901, 22371, 48670, 44751, 33947, 11542, 18276, 6605, 37936] [1, 7, 9, 3, 1, 6, 2, 11, 7]\n",
            "{'ADVERB': 1, 'ADJECTIVE': 2, 'VERB': 3, 'X': 4, 'NUMBER': 5, 'DETERMINER': 6, 'PUNCT': 7, 'CONJUNCTION': 8, 'PRONOUN': 9, 'PREPOSITION': 10, 'NOUN': 11, '[PAD]': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk0ZTHkvplxD",
        "outputId": "84bb8264-3222-4913-e43d-e76bcc4d2cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences as ps\n",
        "def pad_sequences(train_X, train_y):\n",
        "  \"\"\"\n",
        "  Use keras's pad_sequences method to pad zeros to each list within both lists of lists. You can define any large value as the max length \n",
        "  or use the length of the largest sequence in the entire corpus to be the max length.\n",
        "  \"\"\"\n",
        "  train_X = ps(train_X, padding='post', value = 0)\n",
        "  train_y = ps(train_y, padding='post', value= 0)\n",
        "  MAX_LENGTH = len(train_X[0])\n",
        "  return train_X, train_y, MAX_LENGTH\n",
        "train_X, train_y, MAX_LENGTH = pad_sequences(train_X, train_y)\n",
        "print(len(train_X[0]))\n",
        "print(len(train_y[5]))\n",
        "print(MAX_LENGTH)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180\n",
            "180\n",
            "180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edy9gTV6qIhv",
        "outputId": "7c6d246c-0671-4598-81af-11531dc3ef1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer, Activation, Embedding, Bidirectional, LSTM, Dense, TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def define_model(MAX_LENGTH):  \n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(input_shape=(MAX_LENGTH, ))) # MAX_LENGTH is the max length of each sequence, as output by previous method\n",
        "  model.add(Embedding(len(word2idx), 128, input_length=MAX_LENGTH))\n",
        "  model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "  model.add(TimeDistributed(Dense(len(tag2idx))))\n",
        "\n",
        "  \"\"\" \n",
        "  Add your layers here:\n",
        "\n",
        "  \"\"\"\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "  \n",
        "  print (model.summary())\n",
        "  return model\n",
        "\n",
        "# call the function here\n",
        "\n",
        "model = define_model(MAX_LENGTH)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 180, 128)          6366976   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 180, 512)          788480    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 180, 12)           6156      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 180, 12)           0         \n",
            "=================================================================\n",
            "Total params: 7,161,612\n",
            "Trainable params: 7,161,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vfy9nimq3Sr",
        "outputId": "2d2ce52e-f8bd-4bda-d21d-468a61ed0a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical as tc \n",
        "def to_categorical(sequences, categories = 11):\n",
        "    \"\"\"\n",
        "    one hot encode your tags\n",
        "    POS tag list = [1, 2, 1, 3]\n",
        "    One-hot encoded list = [[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1]]\n",
        "    \"\"\"\n",
        "    return tc(np.array(sequences), categories)\n",
        "\n",
        "\n",
        "# call the function here\n",
        "train_y = to_categorical(train_y, categories = len(tag2idx))\n",
        "print(train_y[0])\n",
        "print(len(train_y[0][0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqUS--hrHqp",
        "outputId": "9a677b55-5c4c-4d3d-bb10-eda24422f4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(model, train_X, train_y):\n",
        "  \"\"\"\n",
        "  train the model here calling fit(). If you don't want to see the training logs, you can set verbose to False.\n",
        "  \"\"\"\n",
        "  model.fit(train_X, train_y, batch_size=128, epochs=40, validation_split=0.2 )\n",
        "  return model\n",
        "\n",
        "model = train(model, train_X, train_y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 0.1925 - accuracy: 0.9436 - val_loss: 0.0272 - val_accuracy: 0.9929\n",
            "Epoch 2/40\n",
            "359/359 [==============================] - 40s 110ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
            "Epoch 3/40\n",
            "359/359 [==============================] - 39s 110ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0118 - val_accuracy: 0.9962\n",
            "Epoch 4/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0114 - val_accuracy: 0.9964\n",
            "Epoch 5/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0116 - val_accuracy: 0.9964\n",
            "Epoch 6/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0118 - val_accuracy: 0.9964\n",
            "Epoch 7/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0126 - val_accuracy: 0.9963\n",
            "Epoch 8/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0131 - val_accuracy: 0.9964\n",
            "Epoch 9/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0141 - val_accuracy: 0.9963\n",
            "Epoch 10/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
            "Epoch 11/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0158 - val_accuracy: 0.9962\n",
            "Epoch 12/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0170 - val_accuracy: 0.9962\n",
            "Epoch 13/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 7.9754e-04 - accuracy: 0.9998 - val_loss: 0.0179 - val_accuracy: 0.9961\n",
            "Epoch 14/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 6.5996e-04 - accuracy: 0.9998 - val_loss: 0.0190 - val_accuracy: 0.9960\n",
            "Epoch 15/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 5.4486e-04 - accuracy: 0.9999 - val_loss: 0.0198 - val_accuracy: 0.9960\n",
            "Epoch 16/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 4.3936e-04 - accuracy: 0.9999 - val_loss: 0.0208 - val_accuracy: 0.9960\n",
            "Epoch 17/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 3.6339e-04 - accuracy: 0.9999 - val_loss: 0.0217 - val_accuracy: 0.9960\n",
            "Epoch 18/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 3.2633e-04 - accuracy: 0.9999 - val_loss: 0.0230 - val_accuracy: 0.9959\n",
            "Epoch 19/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 3.2510e-04 - accuracy: 0.9999 - val_loss: 0.0229 - val_accuracy: 0.9960\n",
            "Epoch 20/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 2.7877e-04 - accuracy: 0.9999 - val_loss: 0.0243 - val_accuracy: 0.9957\n",
            "Epoch 21/40\n",
            "359/359 [==============================] - 40s 111ms/step - loss: 2.5380e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9959\n",
            "Epoch 22/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 2.7121e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9959\n",
            "Epoch 23/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 2.3444e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9958\n",
            "Epoch 24/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 2.3938e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9959\n",
            "Epoch 25/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 2.4328e-04 - accuracy: 0.9999 - val_loss: 0.0253 - val_accuracy: 0.9959\n",
            "Epoch 26/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 1.7905e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9959\n",
            "Epoch 27/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 1.3110e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9960\n",
            "Epoch 28/40\n",
            "359/359 [==============================] - 40s 113ms/step - loss: 1.0153e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9958\n",
            "Epoch 29/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 8.6951e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9959\n",
            "Epoch 30/40\n",
            "359/359 [==============================] - 40s 113ms/step - loss: 9.6973e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9959\n",
            "Epoch 31/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 2.6077e-04 - accuracy: 0.9999 - val_loss: 0.0269 - val_accuracy: 0.9959\n",
            "Epoch 32/40\n",
            "359/359 [==============================] - 40s 113ms/step - loss: 3.0583e-04 - accuracy: 0.9999 - val_loss: 0.0272 - val_accuracy: 0.9959\n",
            "Epoch 33/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 1.6512e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9960\n",
            "Epoch 34/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9960\n",
            "Epoch 35/40\n",
            "359/359 [==============================] - 41s 113ms/step - loss: 7.0360e-05 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9960\n",
            "Epoch 36/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 6.4493e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9960\n",
            "Epoch 37/40\n",
            "359/359 [==============================] - 40s 113ms/step - loss: 6.2517e-05 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9960\n",
            "Epoch 38/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 6.3470e-05 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9959\n",
            "Epoch 39/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 7.3170e-05 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9959\n",
            "Epoch 40/40\n",
            "359/359 [==============================] - 40s 112ms/step - loss: 2.4343e-04 - accuracy: 0.9999 - val_loss: 0.0281 - val_accuracy: 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h__vBjmqrTzC",
        "outputId": "0bf0a28a-263c-4d26-f36e-785fe49a64d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences as ps\n",
        "import numpy as np\n",
        "import sys\n",
        "def test(model, sentence):\n",
        "  \"\"\"\n",
        "  Take in a sentence as input and outputs its POST tags. \n",
        "  \"\"\"\n",
        "  input = []\n",
        "  for token in sentence:\n",
        "    if token not in word2idx:\n",
        "      sys.exit('Token \"'+ token + '\" not in training corpus')\n",
        "    input.append(word2idx[token])\n",
        "  test_X = []\n",
        "  test_X.append(input)\n",
        "  test_X = ps(np.array(test_X), padding='post', value = 0, maxlen=MAX_LENGTH)\n",
        "  output = model.predict(test_X)\n",
        "\n",
        "  result = []\n",
        "  for idx in range(0, len(sentence)):\n",
        "    result.append(idx2tag[np.argmax(output[0][idx])])\n",
        "  return result     \n",
        "\n",
        "sentence1 = [\"the\", \"secretariat\", \"is\", \"expected\" ,\"to\" ,\"race\" ,\"tomorrow\", \".\" ]\n",
        "tags = test(model, sentence1)\n",
        "print (tags)\n",
        "sentence2 = [\"people\",\"continue\", \"to\", \"inquire\", \"the\", \"reason\", \"for\", \"the\" ,\"race\", \"for\", \"outer\", \"space\", \".\"]\n",
        "tags = test(model, sentence2)\n",
        "print (tags)\n",
        "s3 = [\"people\", \"race\",\"tomorrow\", \".\"]\n",
        "tags = test(model,s3)\n",
        "print(tags)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['DETERMINER', 'NOUN', 'VERB', 'VERB', 'X', 'VERB', 'NOUN', 'PUNCT']\n",
            "['NOUN', 'VERB', 'X', 'VERB', 'DETERMINER', 'NOUN', 'PREPOSITION', 'DETERMINER', 'NOUN', 'PREPOSITION', 'ADJECTIVE', 'NOUN', 'PUNCT']\n",
            "['NOUN', 'VERB', 'NOUN', 'PUNCT']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}